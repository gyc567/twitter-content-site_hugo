#!/usr/bin/env python3
"""
ä»…æµ‹è¯•Twitter APIéƒ¨åˆ†ï¼Œä¸éœ€è¦OpenAI
"""

import os
import requests
from datetime import datetime
from typing import List, Dict
from pathlib import Path
import re
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®
TWITTER_API_KEY = os.environ.get('TWITTER_API_KEY')

class TwitterTrendFetcher:
    """Twitterè¶‹åŠ¿è·å–å™¨"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.headers = {
            'X-API-Key': api_key,
            'User-Agent': 'TwitterTrendBot/1.0'
        }
    
    def get_trending_topics(self, query: str = "trending", max_results: int = 100) -> List[Dict]:
        """
        è·å–è¶‹åŠ¿è¯é¢˜
        ä½¿ç”¨æ–°çš„Twitter APIæ¥å£
        """
        url = "https://api.twitterapi.io/twitter/tweet/advanced_search"
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        params = {
            'query': query,
            'max_results': max_results,
            'sort_order': 'relevancy'
        }
        
        try:
            print(f"ğŸ” æ­£åœ¨è¯·æ±‚API: {url}")
            print(f"ğŸ“Š æŸ¥è¯¢å‚æ•°: {params}")
            
            response = requests.get(url, headers=self.headers, params=params)
            
            print(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code != 200:
                print(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.text}")
                return self._get_fallback_trends()
            
            response.raise_for_status()
            data = response.json()
            
            print(f"âœ… APIå“åº”æˆåŠŸ")
            print(f"ğŸ“„ å“åº”æ•°æ®é”®: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
            
            # åˆ†ææ•°æ®å¹¶æå–çƒ­é—¨è¯é¢˜
            # APIè¿”å›çš„æ•°æ®åœ¨'tweets'é”®ä¸‹ï¼Œä¸æ˜¯'data'
            tweets = data.get('tweets', data.get('data', []))
            trends = self._analyze_trends(tweets)
            return trends[:3]  # è¿”å›å‰3ä¸ªçƒ­é—¨è¯é¢˜
            
        except Exception as e:
            print(f"âŒ è·å–Twitterè¶‹åŠ¿å¤±è´¥: {e}")
            print(f"é”™è¯¯è¯¦æƒ…: {response.text if 'response' in locals() else 'No response'}")
            # è¿”å›å¤‡ç”¨çƒ­é—¨è¯é¢˜
            return self._get_fallback_trends()
    
    def _analyze_trends(self, tweets: List[Dict]) -> List[Dict]:
        """åˆ†ææ¨æ–‡æå–è¶‹åŠ¿"""
        print(f"ğŸ“ åˆ†æ {len(tweets)} æ¡æ¨æ–‡...")
        
        if not tweets:
            print("âš ï¸  æ²¡æœ‰æ¨æ–‡æ•°æ®ï¼Œä½¿ç”¨å¤‡ç”¨è¶‹åŠ¿")
            return self._get_fallback_trends()
        
        # æ˜¾ç¤ºå‰å‡ æ¡æ¨æ–‡ç¤ºä¾‹
        for i, tweet in enumerate(tweets[:3], 1):
            text = tweet.get('text', 'No text')[:100]
            print(f"   æ¨æ–‡ {i}: {text}...")
        
        topic_scores = {}
        
        for tweet in tweets:
            # æå–è¯é¢˜æ ‡ç­¾å’Œä¸Šä¸‹æ–‡
            text = tweet.get('text', '')
            
            # æ ¹æ®æ–°APIç»“æ„è·å–äº’åŠ¨æ•°æ®
            # å¦‚æœAPIè¿”å›çš„æ•°æ®ç»“æ„ä¸åŒï¼Œéœ€è¦ç›¸åº”è°ƒæ•´
            metrics = tweet.get('public_metrics', {})
            if not metrics:
                # å°è¯•å…¶ä»–å¯èƒ½çš„å­—æ®µå
                metrics = {
                    'retweet_count': tweet.get('retweet_count', 0),
                    'like_count': tweet.get('favorite_count', 0) or tweet.get('like_count', 0),
                    'reply_count': tweet.get('reply_count', 0)
                }
            
            score = (
                metrics.get('retweet_count', 0) * 2 +
                metrics.get('like_count', 0) +
                metrics.get('reply_count', 0) * 1.5
            )
            
            # æå–hashtags
            hashtags = re.findall(r'#\w+', text)
            if not hashtags:
                # å¦‚æœæ²¡æœ‰hashtagï¼Œä½¿ç”¨å…³é”®è¯ä½œä¸ºè¯é¢˜
                words = re.findall(r'\b[A-Za-z]{3,}\b', text)
                hashtags = [f"#{word}" for word in words[:2]]
            
            for tag in hashtags:
                if tag not in topic_scores:
                    topic_scores[tag] = {'score': 0, 'tweets': []}
                topic_scores[tag]['score'] += score
                topic_scores[tag]['tweets'].append(text[:200])
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯é¢˜ï¼Œåˆ›å»ºä¸€äº›é€šç”¨è¯é¢˜
        if not topic_scores:
            return self._create_generic_trends(tweets)
        
        # æ’åºå¹¶è¿”å›
        sorted_topics = sorted(
            topic_scores.items(),
            key=lambda x: x[1]['score'],
            reverse=True
        )
        
        print(f"ğŸ† æ‰¾åˆ° {len(sorted_topics)} ä¸ªè¯é¢˜")
        
        return [
            {
                'topic': topic[0],
                'score': topic[1]['score'],
                'sample_tweets': topic[1]['tweets'][:3]
            }
            for topic in sorted_topics[:10]
        ]
    
    def _create_generic_trends(self, tweets: List[Dict]) -> List[Dict]:
        """ä»æ¨æ–‡ä¸­åˆ›å»ºé€šç”¨è¶‹åŠ¿è¯é¢˜"""
        if not tweets:
            return []
        
        # æå–æœ€å¸¸è§çš„è¯æ±‡ä½œä¸ºè¯é¢˜
        all_words = []
        for tweet in tweets[:10]:  # åªåˆ†æå‰10æ¡æ¨æ–‡
            text = tweet.get('text', '')
            words = re.findall(r'\b[A-Za-z]{4,}\b', text.lower())
            all_words.extend(words)
        
        # ç»Ÿè®¡è¯é¢‘
        word_count = {}
        for word in all_words:
            if word not in ['this', 'that', 'with', 'have', 'will', 'from', 'they', 'been', 'said']:
                word_count[word] = word_count.get(word, 0) + 1
        
        # åˆ›å»ºè¯é¢˜
        trends = []
        for word, count in sorted(word_count.items(), key=lambda x: x[1], reverse=True)[:5]:
            trends.append({
                'topic': f"#{word.capitalize()}",
                'score': count * 100,
                'sample_tweets': [tweet.get('text', '')[:200] for tweet in tweets[:3]]
            })
        
        return trends
    
    def _get_fallback_trends(self) -> List[Dict]:
        """è·å–å¤‡ç”¨è¶‹åŠ¿ï¼ˆç”¨äºAPIå¤±è´¥æ—¶ï¼‰"""
        return [
            {
                'topic': '#Technology',
                'score': 1000,
                'sample_tweets': ['Latest tech innovations...']
            },
            {
                'topic': '#AI',
                'score': 900,
                'sample_tweets': ['AI developments today...']
            },
            {
                'topic': '#Climate',
                'score': 800,
                'sample_tweets': ['Climate change updates...']
            }
        ]

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æµ‹è¯•Twitter APIé›†æˆ")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not TWITTER_API_KEY:
        print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®TWITTER_API_KEYç¯å¢ƒå˜é‡")
        print("ğŸ’¡ åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ : TWITTER_API_KEY=your_api_key_here")
        return
    
    print(f"âœ… Twitter API Keyå·²è®¾ç½®: {TWITTER_API_KEY[:10]}...")
    
    # åˆå§‹åŒ–ç»„ä»¶
    fetcher = TwitterTrendFetcher(TWITTER_API_KEY)
    
    # è·å–çƒ­é—¨è¯é¢˜
    print("\nğŸ” è·å–Twitterçƒ­é—¨è¯é¢˜...")
    trends = fetcher.get_trending_topics()
    
    if not trends:
        print("âŒ æœªèƒ½è·å–åˆ°çƒ­é—¨è¯é¢˜")
        return
    
    print(f"\nğŸ‰ æˆåŠŸæ‰¾åˆ° {len(trends)} ä¸ªçƒ­é—¨è¯é¢˜:")
    print("=" * 50)
    
    # æ˜¾ç¤ºè¯é¢˜è¯¦æƒ…
    for i, trend in enumerate(trends, 1):
        print(f"\nğŸ“ˆ è¯é¢˜ {i}: {trend['topic']}")
        print(f"   è¯„åˆ†: {trend['score']}")
        print(f"   ç¤ºä¾‹æ¨æ–‡:")
        for j, tweet in enumerate(trend.get('sample_tweets', []), 1):
            print(f"     {j}. {tweet[:100]}...")
    
    print("\n" + "=" * 50)
    print("âœ… Twitter APIæµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()